---
layout: post
title: What is Responsible AI?
date: 2023-11-28 07:59:55.000000000 -06:00
type: post
parent_id: '0'
published: true
password: ''
status: publish
categories: []
tags: []
meta:
  _edit_last: '10'
  _genesis_scripts_body_position: bottom
  _yoast_wpseo_estimated-reading-time-minutes: ''
  _yoast_wpseo_wordproof_timestamp: ''
  footnotes: ''
  _wp_old_date: '2023-11-27'
  _yoast_wpseo_primary_category: '1'
author:
  login: saracarl
  email: saracarl@gmail.com
  display_name: Sara Brumfield
  first_name: Sara
  last_name: Brumfield
permalink: "/what-is-responsible-ai/"
---
<p><!-- wp:paragraph --></p>
<p>I recently returned from the AI4LAM/Fantastic Futures conference, where the goal of ethical or responsible AI was a theme in a number of the presentations. For an implementer like me, however, responsible AI can't be just a call for action. I need examples, criteria, how-tos on how to build ethical AI solutions. At this stage of the AI game, that's not always obvious -- to me, or to the folks calling for this responsibility in AI.</p>
<p><!-- /wp:paragraph --></p>
<p><!-- wp:paragraph --></p>
<p>One presentation, however, gave me a list! Scott Young and Jason Clark from Montana State are part of an <a data-cke-saved-href="https://www.lib.montana.edu/responsible-ai/" href="https://www.lib.montana.edu/responsible-ai/" target="_blank" rel="noopener">IMLS-funded project on Responsible AI</a>; they had conducted a workshop where they asked participants what an irresponsible AI project at a university library would look like. Framed that way -- such a simple, but powerful inversion -- they developed a list that technologists like me could use as a roadmap to more ethical AI projects:</p>
<p><!-- /wp:paragraph --></p>
<p><!-- wp:list --></p>
<ul><!-- wp:list-item --></p>
<li>Boast about the gain of staff time to administrators &amp; suggest they can replace staff with machines.</li>
<p><!-- /wp:list-item --></p>
<p><!-- wp:list-item --></p>
<li>Lack of integration into existing digital preservation infrastructures; no consideration of storage space or preservation</li>
<p><!-- /wp:list-item --></p>
<p><!-- wp:list-item --></p>
<li>Ignore existing workflows and procedures</li>
<p><!-- /wp:list-item --></p>
<p><!-- wp:list-item --></p>
<li>Abdicate all design to computer science faculty -- they have the AI expertise</li>
<p><!-- /wp:list-item --></p>
<p><!-- wp:list-item --></p>
<li>Metadata terms determined by natural language processing (AI) without human input; No interrogation of natural language processing schema</li>
<p><!-- /wp:list-item --></p>
<p><!-- wp:list-item --></p>
<li>No considerations of whether these objects should be made public or computationally available; no review of the type of content or the people depicted; release the model without caveats or notes on limitations</li>
<p><!-- /wp:list-item --></p>
<p><!-- wp:list-item --></p>
<li>No consideration of data scraping by large language models</li>
<p><!-- /wp:list-item --></p>
<p><!-- wp:list-item --></p>
<li>No internal discussion about the ethical responsibilities of using AI for this purpose.</li>
<p><!-- /wp:list-item --></p>
<p><!-- wp:list-item --></p>
<li>No ethical or value-driven ground-truthing with computer science</li>
<p><!-- /wp:list-item --></p>
<p><!-- wp:list-item --></p>
<li>No human review of metadata or OCR; don't consult collections staff about the decisions to outsource; disregard collections staff questions or potential input on how the metadata should be scoped</li>
<p><!-- /wp:list-item --></p>
<p><!-- wp:list-item --></p>
<li>No accuracy checks</li>
<p><!-- /wp:list-item --></p>
<p><!-- wp:list-item --></p>
<li>No user testing</li>
<p><!-- /wp:list-item --></ul>
<p><!-- /wp:list --></p>
<p><!-- wp:paragraph --></p>
<p>This "what not to do" list is great! Many of these scenarios are what I'd call "good software design"; only some are specific to AI. But I'm thrilled to have a list of concerns so what we build is more responsible.</p>
<p><!-- /wp:paragraph --></p>
