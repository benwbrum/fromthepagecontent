---
layout: post
title: Archives as an Antidote for ChatGPT
date: 2023-03-20 10:27:51.000000000 -05:00
type: post
parent_id: '0'
published: true
password: ''
status: publish
categories: []
tags: []
meta:
  _edit_last: '10'
  _genesis_scripts_body_position: bottom
  _yoast_wpseo_primary_category: '1'
  _yoast_wpseo_estimated-reading-time-minutes: '3'
  _yoast_wpseo_wordproof_timestamp: ''
  _yoast_wpseo_content_score: '30'
author:
  login: saracarl
  email: saracarl@gmail.com
  display_name: Sara Brumfield
  first_name: Sara
  last_name: Brumfield
permalink: "/archives-as-an-antidote-for-chatgpt/"
---
<p><!-- wp:paragraph --></p>
<p>I wanted to write this month about ChatGPT, and how archives are about as anti-ChatGPT as you can get. Archives can provide learning experiences that ChatGPT can’t fake.</p>
<p><!-- /wp:paragraph --></p>
<p><!-- wp:paragraph --></p>
<p>First, a simplification that’s useful in thinking about what ChatGPT (and its ilk) can – and can’t – do. ChatGPT is, in technical terms, a “large language model”. That means that the creators fed it massive amounts of text: books, people arguing on the internet, your favorite travel writer, all of the code repository Github. That large language model can generate a sequence of words – “language” – that, based on statistics, has a pretty good chance of being language that makes sense. Sense-making is what humans have always done, and I think it’s an exaggeration in this case, because it can’t really make sense of the world – it can just answer questions (or prompts that you construct with the specificity of a wizard casting a spell). A friend refers to it as a really advanced autocomplete.</p>
<p><!-- /wp:paragraph --></p>
<p><!-- wp:paragraph --></p>
<p>That's not to say it isn't impressive! My teenager dropped one of last year’s AP English prompts in, and ChatGPT produced a very passable essay on the significance of the green light in the Great Gatsby. We’ve also been blown away when <a href="https://github.com/tdwg/dwc/issues/32#issuecomment-1344756915" target="_blank" rel="noreferrer noopener">Deb Paul turned OCR of a specimen card into DarwinCore structured data</a>. ChatGPT is <strong>good </strong>at structure.</p>
<p><!-- /wp:paragraph --></p>
<p><!-- wp:paragraph --></p>
<p>Because it’s good at structure, and basically making very sophisticated predictions based on a combination of a huge corpus of training text and statistics, it’s <strong>boring</strong>. It reinforces the status quo of its training data. Ben, to the amusement of our family, asked ChatGPT multiple times and ways to write a story about an astronaut and a dinosaur. Every single time the astronaut was named Tom. The stories were almost caricatures of 1950s sci-fi, with a predictable and boring storyline (singular). ChatGPT is not replacing creative writing anytime soon.</p>
<p><!-- /wp:paragraph --></p>
<p><!-- wp:paragraph --></p>
<p>Anything ChatGPT tells you is based on the known. Not just the known, but the English language material that’s been recorded, digitized, analyzed and fed in as training data. It’s derivative – it has to be. The antidote is the <strong>unknown</strong> – the novel, the unexpected, the counter-intuitive and the surprising. Archives are full of material that hasn’t been read in 20, 200, 2000 years. ChatGPT doesn’t know about it, so any interpretive or analytical work done with archival material will have to contain a decent amount of original work and thought.</p>
<p><!-- /wp:paragraph --></p>
<p><!-- wp:paragraph --></p>
<p>Here’s a handful of ideas that – for now, at least – are ChatGPT-proof.</p>
<p><!-- /wp:paragraph --></p>
<p><!-- wp:list --></p>
<ul><!-- wp:list-item --></p>
<li>Transcribe. Puzzling out handwriting might not be a core skill for students, but it forces a deep reading of a text. Asking for observations on the process &amp; material makes them reflect on the task – something we’ve learned large language models are particularly bad at.</li>
<p><!-- /wp:list-item --></p>
<p><!-- wp:list-item --></p>
<li>Put material in historical context. I think it still requires humans to make connections between the spoken: “No butter at the store” and the unspoken: “rationing”. Asking for examples that speak to the historical context of the documents, forcing students to read deeply and look for clues. Historical detective work is fun, too.&nbsp;</li>
<p><!-- /wp:list-item --></p>
<p><!-- wp:list-item --></p>
<li>Compare the use and choice of language in the document. How does it compare to the student’s language use and choice? How is it similar in tone, if not content?</li>
<p><!-- /wp:list-item --></p>
<p><!-- wp:list-item --></p>
<li>Explore the materiality. What was something written on? Why would that be the material? How did the writer use that material? Did they reuse material (from a palimpsest to a daybook from a previous year)? What does that say about the technology and supply at the time? Did they write different material back-to-front than front-to-back? It’s hard for any digital format to capture all of these nuances.</li>
<p><!-- /wp:list-item --></p>
<p><!-- wp:list-item --></p>
<li>Look for commonalities. What events, emotions, or expenses in the documents remind students of their own experiences? What resonates? What is so far outside of the student’s experience so as to be foreign?</li>
<p><!-- /wp:list-item --></ul>
<p><!-- /wp:list --></p>
